{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "from os import environ, chdir\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import models, layers, optimizers, callbacks\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import models, layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:348: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3304 images belonging to 14 classes.\n",
      "Found 700 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setting Image and Data Generators\n",
    "train_idg = ImageDataGenerator (rescale=1. / 255,\n",
    "\n",
    "                                featurewise_std_normalization=True,horizontal_flip=True,\n",
    "                                zoom_range=0.2,\n",
    "                                shear_range=0.2,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "\n",
    "train_g = train_idg.flow_from_directory (directory=r'E:\\Zinc-lead\\Zinc-lead\\train',\n",
    "                                         target_size=(400,400),class_mode='categorical',\n",
    "                                         batch_size=10,shuffle=True)\n",
    "\n",
    "valid_idg = ImageDataGenerator (rescale=1. / 255)\n",
    "\n",
    "valid_g = valid_idg.flow_from_directory (directory=r'E:\\Zinc-lead\\Zinc-lead\\valid',\n",
    "                                         target_size=(400,400),class_mode='categorical',\n",
    "                                         batch_size=10,shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 398, 398, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 199, 199, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 199, 199, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 197, 197, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 98, 98, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 96, 96, 96)        55392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 48, 48, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 48, 48, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 46, 46, 96)        83040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 23, 23, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 23, 23, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 21, 21, 128)       110720    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                1806      \n",
      "=================================================================\n",
      "Total params: 3,581,966\n",
      "Trainable params: 3,581,134\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN Architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(400,400,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(14, activation = 'sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Loss function and Optimizer method\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 108s 5s/step - loss: 0.4939 - accuracy: 0.8246 - val_loss: 0.4143 - val_accuracy: 0.8679\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 107s 5s/step - loss: 0.3869 - accuracy: 0.8732 - val_loss: 0.4083 - val_accuracy: 0.8571\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 107s 5s/step - loss: 0.3459 - accuracy: 0.8900 - val_loss: 0.4641 - val_accuracy: 0.9286\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 106s 5s/step - loss: 0.3061 - accuracy: 0.9096 - val_loss: 0.5745 - val_accuracy: 0.9286\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 100s 5s/step - loss: 0.2819 - accuracy: 0.9039 - val_loss: 0.5630 - val_accuracy: 0.9286\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 100s 5s/step - loss: 0.2915 - accuracy: 0.9071 - val_loss: 0.6668 - val_accuracy: 0.8571\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 99s 5s/step - loss: 0.2858 - accuracy: 0.9057 - val_loss: 0.5952 - val_accuracy: 0.8643\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 99s 5s/step - loss: 0.2618 - accuracy: 0.9161 - val_loss: 0.5762 - val_accuracy: 0.9286\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 98s 5s/step - loss: 0.2476 - accuracy: 0.9118 - val_loss: 0.6913 - val_accuracy: 0.9286\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 100s 5s/step - loss: 0.2456 - accuracy: 0.9143 - val_loss: 0.6239 - val_accuracy: 0.9304\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 100s 5s/step - loss: 0.2454 - accuracy: 0.9136 - val_loss: 0.6269 - val_accuracy: 0.9286\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 100s 5s/step - loss: 0.2251 - accuracy: 0.9239 - val_loss: 0.6240 - val_accuracy: 0.9286\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 99s 5s/step - loss: 0.2141 - accuracy: 0.9271 - val_loss: 1.2518 - val_accuracy: 0.8679\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 106s 5s/step - loss: 0.2300 - accuracy: 0.9196 - val_loss: 0.5371 - val_accuracy: 0.9321\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 98s 5s/step - loss: 0.2351 - accuracy: 0.9175 - val_loss: 0.4133 - val_accuracy: 0.9214\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 108s 5s/step - loss: 0.2045 - accuracy: 0.9275 - val_loss: 0.3143 - val_accuracy: 0.9304\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 101s 5s/step - loss: 0.2191 - accuracy: 0.9216 - val_loss: 0.7285 - val_accuracy: 0.9286\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 100s 5s/step - loss: 0.1980 - accuracy: 0.9307 - val_loss: 0.6783 - val_accuracy: 0.9143\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 98s 5s/step - loss: 0.1797 - accuracy: 0.9382 - val_loss: 0.8127 - val_accuracy: 0.9304\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 99s 5s/step - loss: 0.1921 - accuracy: 0.9311 - val_loss: 0.3388 - val_accuracy: 0.9125\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 99s 5s/step - loss: 0.1834 - accuracy: 0.9321 - val_loss: 0.5086 - val_accuracy: 0.9268\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 107s 5s/step - loss: 0.1843 - accuracy: 0.9346 - val_loss: 0.5120 - val_accuracy: 0.9232\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 105s 5s/step - loss: 0.1816 - accuracy: 0.9339 - val_loss: 0.3801 - val_accuracy: 0.9161\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 108s 5s/step - loss: 0.1750 - accuracy: 0.9293 - val_loss: 0.2202 - val_accuracy: 0.9286\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 102s 5s/step - loss: 0.1798 - accuracy: 0.9368 - val_loss: 0.5474 - val_accuracy: 0.8875\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 105s 5s/step - loss: 0.1612 - accuracy: 0.9393 - val_loss: 0.7650 - val_accuracy: 0.8607\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 107s 5s/step - loss: 0.1760 - accuracy: 0.9325 - val_loss: 0.3257 - val_accuracy: 0.9214\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 99s 5s/step - loss: 0.1572 - accuracy: 0.9421 - val_loss: 0.5137 - val_accuracy: 0.9179\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 95s 5s/step - loss: 0.1720 - accuracy: 0.9339 - val_loss: 0.4462 - val_accuracy: 0.9214\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 93s 5s/step - loss: 0.1726 - accuracy: 0.9404 - val_loss: 0.3341 - val_accuracy: 0.9036\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 96s 5s/step - loss: 0.1744 - accuracy: 0.9382 - val_loss: 0.2587 - val_accuracy: 0.9196\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 96s 5s/step - loss: 0.1562 - accuracy: 0.9361 - val_loss: 0.1528 - val_accuracy: 0.9286\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 97s 5s/step - loss: 0.1497 - accuracy: 0.9425 - val_loss: 0.1976 - val_accuracy: 0.9429\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 103s 5s/step - loss: 0.1544 - accuracy: 0.9432 - val_loss: 0.1336 - val_accuracy: 0.9411\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 99s 5s/step - loss: 0.1613 - accuracy: 0.9400 - val_loss: 0.3068 - val_accuracy: 0.9179\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 103s 5s/step - loss: 0.1658 - accuracy: 0.9363 - val_loss: 0.1105 - val_accuracy: 0.9500\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 113s 6s/step - loss: 0.1600 - accuracy: 0.9396 - val_loss: 0.3995 - val_accuracy: 0.9161\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 107s 5s/step - loss: 0.1586 - accuracy: 0.9368 - val_loss: 1.1966 - val_accuracy: 0.8821\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 110s 6s/step - loss: 0.1451 - accuracy: 0.9439 - val_loss: 1.0011 - val_accuracy: 0.8821\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 110s 5s/step - loss: 0.1486 - accuracy: 0.9439 - val_loss: 0.9103 - val_accuracy: 0.8911\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 109s 5s/step - loss: 0.1422 - accuracy: 0.9471 - val_loss: 0.2609 - val_accuracy: 0.9107\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 109s 5s/step - loss: 0.1429 - accuracy: 0.9496 - val_loss: 0.1080 - val_accuracy: 0.9268\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 108s 5s/step - loss: 0.1310 - accuracy: 0.9496 - val_loss: 0.2899 - val_accuracy: 0.9357\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 108s 5s/step - loss: 0.1409 - accuracy: 0.9436 - val_loss: 0.0484 - val_accuracy: 0.9536\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 109s 5s/step - loss: 0.1347 - accuracy: 0.9443 - val_loss: 0.9039 - val_accuracy: 0.8982\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 110s 5s/step - loss: 0.1392 - accuracy: 0.9439 - val_loss: 0.1526 - val_accuracy: 0.9250\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 106s 5s/step - loss: 0.1321 - accuracy: 0.9479 - val_loss: 1.1631 - val_accuracy: 0.8661\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 97s 5s/step - loss: 0.1221 - accuracy: 0.9514 - val_loss: 0.2646 - val_accuracy: 0.9143\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 97s 5s/step - loss: 0.1259 - accuracy: 0.9496 - val_loss: 0.3829 - val_accuracy: 0.9000\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 98s 5s/step - loss: 0.1223 - accuracy: 0.9504 - val_loss: 0.0917 - val_accuracy: 0.9518\n"
     ]
    }
   ],
   "source": [
    "# Training Options\n",
    "fit = model.fit_generator (generator=train_g, steps_per_epoch=20, epochs=50, verbose=1,\n",
    "                              validation_data=valid_g, validation_steps=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 175 images belonging to 14 classes.\n",
      "Evaluation loss over never seen images is : 0.1512\n",
      "Evaluation accuracy over never seen images is : 93.08%\n"
     ]
    }
   ],
   "source": [
    "#Evaluating model\n",
    "eval_idg = ImageDataGenerator (rescale=1. / 255)\n",
    "eval_g = eval_idg.flow_from_directory (directory=r'E:\\Zinc-lead\\Zinc-lead\\eval',\n",
    "                                         target_size=(400,400),class_mode='categorical',\n",
    "                                         batch_size=32,shuffle=False)\n",
    "eval_loss,eval_acc=model.evaluate_generator(generator=eval_g,steps=1)\n",
    "print('Evaluation loss over never seen images is : {:.4f}' .format(eval_loss))\n",
    "print('Evaluation accuracy over never seen images is : {:4.2f}%' .format(eval_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Model\n",
    "model.save (filepath=r'lead-zinc.h5', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
